{
  
    
        "post0": {
            "title": "fastai - Chapter 1 - Deep Learning in Practice",
            "content": "Deep Learning is for Everyone . . What is Machine Learning ? . A Machine Learning Program . As we learned earlier, machine learning is the science to write programs that learn. Therefore, machine learning could allow you to recognize dogs and cats without telling the program all the characteristics of each one (which is tricky) since the program can learn these. This learning is possible through this model training loop : . . Let&#39;s break down this figure : . The model receives inputs which are the data (the images of dogs and cats). | The model ouputs predictions which looks like : &quot;Dog&quot; or &quot;Cat&quot;. | The performance of the predictions is calculated. | The model is updated according to the performance in order to improve itself. | Architecture and Parameters . . You can notice that we split Model into Architecture and Parameters. The architecture is the functional form of the model and the parameters are some variables that defines how the architecture operates. For example, $y = ax + b$ is an architecture with the parameters $a$ and $b$ that change the behavior of the function. . Labels and Loss . . We can see that now the Performance is split into Labels and Loss. The labels are the (ground) truth. For example, if an image is a dog the label of the image is Dog. Therefore, the labels and the predictions can be compared to determine the performance of the model. Indeed, if the prediction on an image is Cat and the label is Dog, you would know that the model did bad. The loss is this measure of performance thats compares the labels and the predictions so that we can updates the parameters to perform better. . Trained Models . . Once a model is trained. You can treat it as a regular program. . Regular Programming . . def add(a, b): return a + b add(2, 3) . 5 . As you can see this program takes some inputs and outputs results. Indeed, the inputs are $2$ and $3$ and the result, $5$. . What is Deep Neural Network ? . As we learned earlier deep neural network is a kind of machine learning model and &quot;deep&quot; refers to having move than 1 hidden layer (1 input layer → 1+ hidden layer → 1 output layer). This model can solve any problems according to the universal approximation theorem by varying the parameters. Therefore, we need a general &quot;mecanism&quot; to modify these parameters for each problem. This &quot;mecanism&quot; already exists and it is called stochastic gradient descent (SGD). . . Tip: SGD and deep neural networks sounds complex, but they aren&#8217;t ! . How Our Image Recognizer Works . Let&#39;s break down the first lines of code of our image recognizer : . from fastai.vision.all import * . This allows us to use all the tools we will need to code a variety of computer vision models. . PATH = untar_data(URLs.PETS)/&#39;images&#39; PATH . Path(&#39;C:/Users/natha/.fastai/data/oxford-iiit-pet/images&#39;) . This line downloads a dataset from fast.ai datasets collection (if not previously downloaded), extracts it (if not previously extracted) and returns a Path object with the extracted location . def is_cat(x): return x[0].isupper() . Here we define the function is_cat to get the label of an image. Indeed, the function returns True if the image contains a cat since the dataset&#39;s creators set cats&#39;s filenames with an upper case at the beginning. . dls = ImageDataLoaders.from_name_func(path=PATH, fnames=get_image_files(PATH), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224)) . Our model needs to know the kind and the structure of the dataset it&#39;s working with. Therefore, we created a dataloader. Since we are using images, this is an ImageDataLoaders. Also, from_name_func is used, because we are using the name of the files to label our images. . Let&#39;s explain the parameters : . path : where the data is stored | fnames : an object containing the Path objects of the images&#39; filenames | valid_pct : the percentage of data hold out randomly in the validation set (we will talk later about this) | seed : aims to make your code reproductible by always generating the same validation set | label_func : the function use to get the label of the image | item_tfms : a transformation done to each item (in this case each item is resized to 224-pixel square) | . Sidebar: Datasets: Food for Models . In machine learning and deep learning, we can’t do anything without data. So, the people that create datasets for us to train our models on are the (often underappreciated) heroes. Most datasets used in this book took the creators a lot of work to build. . Some of the most useful and important datasets are those that become important academic baselines; that is, datasets that are widely studied by researchers and used to compare algorithmic changes, such as MNIST, CIFAR-10, and ImageNet. . The datasets used in this book have been selected because they provide great examples of the kinds of data that you are likely to encounter, and the academic literature has many examples of model results using these datasets to which you can compare your work. . Sets . In order to evaluate the performance of our models, we need to split our data into sets to prevent &quot;cheating&quot; (overfitting). This cut is based on how fully we want to hide it from the model and ourselves: training data is fully exposed, the validation data is less exposed, and test data is totally hidden. . . Validation Set . If we train a model with all our data and evaluate the model using that same data, we would not be able to tell how well our model can perform on data it hasn’t seen since the model already has all the answers in the training set. Indeed, it could be overfitting. . To avoid this, we split our dataset into two sets: the training set and the validation set which is used only for evaluation (and not for the training). This lets us test that the model learns lessons from the training data that generalize to new data, the validation data. . Test Set . However, we as human can also cheat! Indeed, in realistic scenarios we are likely to explore many versions of a model by choosing various hyperparameters (parameters about parameters) : network architecture, learning rates, data augmentation strategies, and other factors we will discuss in upcoming chapters. So, just as the automatic training process is in danger of overfitting the training data, we are in danger of overfitting the validation data through human trial and error and exploration. . The solution is to introduce another level of even more highly reserved data, the test set. Just as we hold back the validation data from the training process, we must hold back the test set data even ourselves. It cannot be used to improve the model; it can only be used to evaluate the model at the very end of our efforts. . Use Judgment in Defining Sets . A key property of the validation and test sets is that they must be representative of the new data you will see in the future. Therefore, you shouldn&#39;t always choose a random subset of your data. . Exercices . For the following situations, how should you split the training set and the validation set ? . 1. . You are using historical data to build a model to predict the future sales in a chain of Ecuadorian grocery stores as you can see below. . . 2. . In the Kaggle distracted driver competition, the independent variables are pictures of drivers at the wheel of a car, and the dependant variables are categories such as texting, eating, or safely looking ahead. Lots of pictures are of the same drivers in different positions, as we can see in this figure. . . 3. . You are trying to create an algorithm to distinguish dogs and cats for the Kaggle Dogs vs. Cats competition. . 4. . The goal of the Kaggle fisheries competition was to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set of Kaggle on which you&#39;ll do your predictions consisted of boats that didn&#39;t appear in the training data. . Solutions . 1. . . You are using historical data to build a model to predict the future sales in a chain . Therefore, we should take a part of the newest data in our validation set in order to be representative of the new data you will see in the future. . Indeed, a random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you&#39;ll need in production), as we can see : . . 2. . Lots of pictures are of the same drivers in different positions. . The validation data should consists of images of people that don&#39;t appear in the training set in order to be representative of the new data you will see in the future. . Indeed, if you used all the people in training your model, your model might be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc.). . 3. . Randomly is a good answer (since it will keep a good ratio between classes in the sets). . 4. . The test set consisted of boats that didn&#39;t appear in the training data. . This means that you&#39;d want your validation set to include boats that are not in the training set in order to be representative of the new data you will see in the future. . Questionnaires . Go to this link and learn the flash cards. #TODO . This post is highly inspired from Deep Learning for Coders [1]. . [1]J. Howard and S. Gugger, Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD. O’Reilly Media, Incorporated, 2020. | .",
            "url": "https://nathanieldamours.github.io/blog/deep%20learning%20for%20coders/jupyter/2021/12/17/dl_for_coders_01.html",
            "relUrl": "/deep%20learning%20for%20coders/jupyter/2021/12/17/dl_for_coders_01.html",
            "date": " • Dec 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "fastai - Chapter 2 - From Model to Production [Draft]",
            "content": "The six lines of code we saw in the last chapter are just one small part of the process of using deep learning in practice. In this chapter, we&#39;re going to use a computer vision example to look at the end-to-end process of creating a deep learning application. More specifically, we&#39;re going to build a bear classifier! In the process, we&#39;ll discuss the capabilities and constraints of deep learning, explore how to create datasets, look at possible gotchas when using deep learning in practice, and more. Many of the key points will apply equally well to other deep learning problems, such as those in last chapter. If you work through a problem similar in key respects to our example problems, we expect you to get excellent results with little code, quickly. . The Practice of Deep Learning . We&#39;ve seen that deep learning can solve a lot of challenging problems quickly and with little code. However, deep learning isn&#39;t magic! The same 6 lines of code won&#39;t work for every problem anyone can think of today. . We often talk to people who underestimate both the constraints and the capabilities of deep learning. Both of these can be problems: underestimating the capabilities means that you might not even try things that could be very beneficial, and underestimating the constraints might mean that you fail to consider and react to important issues. . The best thing to do is to keep an open mind. Then, it is possible to design a process where you can find the specific capabilities and constraints related to your particular problem as you work through the process. This doesn&#39;t mean making any risky bets — we will show you how you can gradually roll out models so that they don&#39;t create significant risks, and can even backtest them prior to putting them in production. . Starting Your Project . When selecting a project, the most important consideration is data availability. However, the goal is not to find the &quot;perfect&quot; dataset or project, but just to get started and iterate from there. . We also suggest that you iterate from end to end in your project; that is, don&#39;t spend months fine-tuning your model, or polishing the perfect GUI, or labelling the perfect dataset… Instead, complete every step as well as you can in a reasonable amount of time, all the way to the end. By completing the project end to end, you will see where the trickiest bits are, and which bits make the biggest difference to the final result. . As you work through this book, we suggest that you complete lots of small experiments, by running and adjusting the notebooks we provide, at the same time that you gradually develop your own projects. That way, you will be getting experience with all of the tools and techniques that we&#39;re explaining, as we discuss them. . . Tip: To make the most of this book, take the time to experiment between each chapter, be it on your own project or by exploring the notebooks we provide. Then try rewriting those notebooks from scratch on a new dataset. It&#8217;s only by practicing (and failing) a lot that you will get an intuition of how to train a model. . By using the end-to-end iteration approach you will also get a better understanding of how much data you really need. Indeed, for instance, you may find you can only easily get 200 labeled data items. . In an organizational context you will be able to show your colleagues that your idea can really work by showing them a real working prototype. We have repeatedly observed that this is the secret to getting good organizational buy-in for a project. . Since it is easiest to get started on a project where you already have data available, that means it&#39;s probably easiest to get started on a project related to something you are already doing, because you already have data about things that you are doing. For instance, if you work in the music business, you may have access to many recordings. . Sometimes, you have to get a bit creative. Maybe you can find some previous machine learning project, such as a Kaggle competition, that is related to your field of interest. . Sometimes, you have to compromise. Maybe you can&#39;t find the exact data you need for the precise project you have in mind; but you might be able to find something from a similar domain, or measured in a different way, tackling a slightly different problem. . Especially when you are just starting out with deep learning, it&#39;s not a good idea apply deep learning where it has not been before. That&#39;s because if your model does not work at first, you will not know whether it is because you have made a mistake, or if the very problem you are trying to solve is simply not solvable with deep learning. Let&#39;s have a look at the state of deep learning, just so you know what kinds of things deep learning is good at right now. . Gathering Data . The project we&#39;ll be completing in this chapter is a bear detector. It will discriminate between three types of bear: grizzly, black, and teddy bears. You can follow along with this chapter and create your own image recognition application for whatever kinds of objects you&#39;re interested in. In the fast.ai course, thousands of students have presented their work in the course forums, displaying everything from hummingbird varieties in Trinidad to bus types in Panama—one student even created an application that would help his fiancée recognize his 16 cousins during Christmas vacation! . For many types of projects, you may be able to find all the data you need online. At the time of writing, the Google image downloader from this repository is probably the best option for finding and downloading images. . . Note: The downloader allows you to start quickly your DL project and iterate from there. However, you might encounter some issues with it such as some irrelevent images or a lot of duplicate images. Therefore, in your second iteration, during the creation of your dataset, you might use some software such as this one to delete the duplicates. . Here is the code to download our images : . %pip install simple_image_download from simple_image_download import simple_image_download as simp image_downloader = simp.simple_image_download() bear_types = [&#39;grizzly bear&#39;, &#39;black bear&#39;, &#39;teddy bear&#39;] for bear_type in bear_types: image_downloader.download(keywords=bear_type, limit=150) simple_images_path = Path(&#39;simple_images&#39;) image_files = get_image_files(simple_images_path) failed_images = verify_images(image_files) failed_images.map(Path.unlink) . image_files . (#488) [Path(&#39;simple_images/black_bear/black bear_1.png&#39;),Path(&#39;simple_images/black_bear/black bear_10.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_100.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_101.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_102.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_103.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_104.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_105.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_106.jpeg&#39;),Path(&#39;simple_images/black_bear/black bear_107.jpeg&#39;)...] . Our folder has image files, as we&#39;d expect. Let&#39;s open one : . bear_img = Image.open(image_files[0]) bear_img . . Let&#39;s break down this code. . %pip install simple_image_download . This line is used to download images with Bing Image Search, it&#39;s the same thing as doing pip install simple_image_download in your terminal. . from simple_image_download import simple_image_download as simp . Here, we import the simple_image_download as simp from simple_image_download in order to use it to get the images from the web. . image_downloader = simp.simple_image_download() bear_types = [&#39;grizzly bear&#39;, &#39;black bear&#39;, &#39;teddy bear&#39;] for bear_type in bear_types: image_downloader.download(keywords=bear_type, limit=150) . Finally, we iterate over the bear_types in order to download 150 images that will be stored in the simple_images folder. We actually do a Google search with your query and return the first results. . Here&#39;s all the parameter of the download method : . query: String to be searched. | limit: Integer representing the numbers of files to download. | extensions: Set containing the extensions of the files (optional, default is {.jpg, .png, .ico, .gif, .jpeg}). | . image_files = get_image_files(simple_images_path) failed_images = verify_images(image_files) failed_images.map(Path.unlink) . When we download files from the internet, there are a few that are corrupt. To remove all the failed images, you can use unlink on each of them. In this case, no files were corrupted. Note that, like most fastai functions that return a collection, verify_images returns an object of type L, which includes the map method. This calls the passed function on each element of the collection. . Sidebar: Getting Help in Jupyter Notebooks . Jupyter notebooks are great for experimenting and immediately seeing the results of each function, but there is also a lot of functionality to help you figure out how to use different functions, or even directly look at their source code. Here are some other features that are very useful in Jupyter notebooks: . . At any point, if you don&#39;t remember the exact spelling of a function or argument name, you can press Tab to get autocompletion suggestions. . . When inside the parentheses of a function, pressing Shift and Tab simultaneously will display a window with the signature of the function and a short description. Pressing these keys twice will expand the documentation, and pressing them three times will open a full window with the same information at the bottom of your screen. . ?verify_images . Signature: verify_images(fns) Docstring: Find images in `fns` that can&#39;t be opened File: c: users natha anaconda3 envs fastbook lib site-packages fastai vision utils.py Type: function . In a cell, typing ?function_name and executing will show the signature of the function and a short description. . ??verify_images . Signature: verify_images(fns) Source: def verify_images(fns): &#34;Find images in `fns` that can&#39;t be opened&#34; return L(fns[i] for i,o in enumerate(parallel(verify_image, fns)) if not o) File: c: users natha anaconda3 envs fastbook lib site-packages fastai vision utils.py Type: function . In a cell, typing ??function_name and executing will show the signature of the function, a short description, and the source code. . . If you are using the fastai library, we added a doc function for you: executing doc(function_name) in a cell will open a window with the signature of the function, a short description and links to the source code on GitHub and the full documentation of the function in the library docs. . . To get help at any point if you get an error, type %debug in the next cell and execute to open the Python debugger, which will let you inspect the content of every variable and test expressions. . End sidebar . One thing to be aware of in this process: as we discussed in the last chapter, models can only reflect the data used to train them. And the world is full of biased data, which ends up reflected in, for example, Bing Image Search. For instance, let&#39;s say you were interested in creating an app that could help users figure out whether they had healthy skin, so you trained a model on the results of searches for &quot;healthy skin&quot;. Here&#39;s the kinds of results you would get : . . With this as your training data, you would end up not with a healthy skin detector, but a young white woman touching her face detector! Be sure to think carefully about the types of data that you might expect to see in practice in your application, and check carefully to ensure that all these types are reflected in your model&#39;s source data. . Now that we have downloaded some data, we need to assemble it in a format suitable for model training. In fastai, that means creating an object called DataLoaders. . This post is highly inspired from Deep Learning for Coders [1]. . [1]J. Howard and S. Gugger, Deep Learning for Coders with Fastai and Pytorch: AI Applications Without a PhD. O’Reilly Media, Incorporated, 2020. | .",
            "url": "https://nathanieldamours.github.io/blog/deep%20learning%20for%20coders/jupyter/2021/02/15/dl_for_coders_02.html",
            "relUrl": "/deep%20learning%20for%20coders/jupyter/2021/02/15/dl_for_coders_02.html",
            "date": " • Feb 15, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nathanieldamours.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nathanieldamours.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m Nathaniel D’Amours : a software engineering student and a cofounder of the CIA. . .",
          "url": "https://nathanieldamours.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nathanieldamours.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}