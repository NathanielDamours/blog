{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Coders - Chapter 1 [Draft]\n",
    "> An even more top-down approach of the chapter\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Deep Learning for Coders, Jupyter]\n",
    "- image: images/trained_model.png\n",
    "- author: Nathaniel D'Amours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is highly inspired from *Deep Learning for Coders* {% cite howard2020deep %}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning is for Everyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def save_gv(filename, data, is_graph=False):\n",
    "    if not is_graph:\n",
    "        graph_data = gv(data)\n",
    "    else:\n",
    "        graph_data = data\n",
    "    my_graph = graphviz.Source(graph_data)\n",
    "    my_graph.render(filename, format='png', directory=\"my_icons/dl_for_coders_01/\", view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = \"\"\"\n",
    "digraph {\n",
    "    subgraph cluster_ai {\n",
    "        label=\"Artificial Intelligence\";\n",
    "        \"Your calculator\";\n",
    "        subgraph cluster_ml {\n",
    "            label=\"Machine Learning\";\n",
    "            \"Linear Regression\";\n",
    "            subgraph cluster_backend {\n",
    "                label=\"Neural network\";\n",
    "                \"Convolutional neural network\";\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "save_gv(\"ai_ml_nn\", data, is_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/ai_ml_nn.png \"Fig.0 - AI vs ML vs NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Machine Learning Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned earlier, machine learning is the science to write programs that learn. Therefore, machine learning could allow you to recognize dogs and cats without telling the program all the characteristics of each one (which is tricky) since the program can learn these. This learning is possible through this model training loop :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "data = '''ordering=in\n",
    "          Model[shape=box3d width=1 height=0.7]\n",
    "          Inputs [shape=none, width=0.5 height=0.7]\n",
    "          Inputs->Model->Predictions;\n",
    "          Predictions->Performance\n",
    "          Performance->Model[constraint=false label=updates]'''\n",
    "save_gv(\"training\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/training.png \"Fig.1 - The training loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this figure :\n",
    "1. The model receives **inputs** which are the data (the images of dogs and cats).\n",
    "2. The model ouputs **predictions** which looks like : \"Dog\" or \"Cat\".\n",
    "3. The **performance** of the predictions is calculated.\n",
    "4. The **model** is updated according to the performance in order to improve itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "data = '''ordering=in\n",
    "          Architecture[shape=box3d width=1 height=0.7]\n",
    "          # Inputs [shape=none,label=\"\" width=0.5 height=0.7]\n",
    "          Inputs->Architecture->Predictions; Parameters->Architecture; Predictions->Performance\n",
    "          Performance->Parameters[constraint=false label=updates]'''\n",
    "save_gv(\"training_arch_param\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/training_arch_param.png \"Fig.2 - Split the model into architecture and parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that we split *Model* into *Architecture* and *Parameters*. The architecture is the functional form of the model and the parameters are some variables that defines how the architecture operates. For example, $y = ax + b$ is an architecture with the parameters $a$ and $b$ that change the behavior of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = '''ordering=in\n",
    "          Model[shape=box3d width=1 height=0.7 label=Architecture]\n",
    "          Inputs->Model->Predictions; Parameters->Model;Labels->Loss; Predictions->Loss\n",
    "          Loss->Parameters[constraint=false label=updates]'''\n",
    "save_gv(\"training_labels_loss\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/training_labels_loss.png \"Fig.3 - Split the performance into labels and loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We can see that now the *Performance* is split into *Labels* and *Loss*. The labels are the (ground) truth. For example, if an image is a dog the label of the image is *Dog*. Therefore, the labels and the predictions can be compared to determine the performance of the model. Indeed, if the prediction on an image is *Cat* and the label is *Dog*, you would know that the model did bad. The loss is this measure of performance thats compares the labels and the predictions so that we can updates the parameters to perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = '''Model[shape=box3d width=1 height=0.7]\n",
    "          Inputs->Model->Predictions'''\n",
    "save_gv(\"trained_model\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/trained_model.png \"Fig.4 - A trained model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model is trained. You can treat it as a regular program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = '''Program[shape=box3d width=1 height=0.7]\n",
    "          Inputs->Program->Results'''\n",
    "save_gv(\"regular_program\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/regular_program.png \"Fig.5 - A regular program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this program takes some inputs and outputs results. Indeed, the inputs are $2$ and $3$ and the result, $5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Deep Neural Network ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned earlier deep neural network is a kind of machine learning model and \"deep\" refers to having move than 1 hidden layer (1 input layer → 1+ hidden layer → 1 output layer). This model can solve any problems according to the [*universal approximation theorem*](https://en.wikipedia.org/wiki/Universal_approximation_theorem) by varying the parameters. Therefore, we need a general \"mecanism\" to modify these parameters for each problem. This \"mecanism\" already exists and it is called stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: SGD and deep neural networks sounds complex, but they aren't !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Our Image Recognizer Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the first lines of code of our image recognizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to use all the tools we will need to code a variety of computer vision models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('C:/Users/natha/.fastai/data/oxford-iiit-pet/images')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = untar_data(URLs.PETS)/'images'\n",
    "PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line downloads a dataset from fast.ai datasets collection (if not previously downloaded), extracts it (if not previously extracted) and returns a Path object with the extracted location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat(x):\n",
    "    return x[0].isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the function `is_cat` to get the label of an image. Indeed, the function returns `True` if the image contains a cat since the dataset's creators set cats's filenames with an upper case at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "dls = ImageDataLoaders.from_name_func(path=PATH,\n",
    "                                      fnames=get_image_files(PATH),\n",
    "                                      valid_pct=0.2,\n",
    "                                      seed=42,\n",
    "                                      label_func=is_cat,\n",
    "                                      item_tfms=Resize(224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model needs to know the kind and the structure of the dataset it's working with. Therefore, we created a dataloader. Since we are using images, this is an `ImageDataLoaders`. Also, `from_name_func` is used, because we are using the name of the files to label our images.\n",
    "\n",
    "Let's explain the parameters :\n",
    "- `path` : where the data is stored\n",
    "- `fnames` : an object containing the Path objects of the images' filenames\n",
    "- `valid_pct` : the percentage of data hold out randomly in the validation set (we will talk later about this)\n",
    "- `seed` : aims to make your code reproductible by always generating the same validation set\n",
    "- `label_func` : the function use to get the label of the image\n",
    "- `item_tfms` : a transformation done to each item (in this case each item is resized to 224-pixel square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- page 42  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sidebar: Datasets: Food for Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and deep learning, we can’t do anything without data. So, the people that create datasets for us to train our models on are the (often underappreciated) heroes. Most datasets used in this book took the creators a lot of work to build.\n",
    "\n",
    "Some of the most useful and important datasets are those that become important *academic baselines*; that is, datasets that are widely studied by researchers and used to compare algorithmic changes, such as MNIST, CIFAR-10, and ImageNet.\n",
    "\n",
    "The datasets used in this book have been selected because they provide great examples of the kinds of data that you are likely to encounter, and the academic literature has many examples of model results using these datasets to which you can compare your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of our models, we need to split our data into sets to prevent \"cheating\" (overfitting). This cut is based on how fully we want to hide it from the model and ourselves: *training* data is fully exposed, the *validation* data is less exposed, and *test* data is totally hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "data = \"\"\"\n",
    "    digraph {\n",
    "        compound=true;\n",
    "        subgraph cluster_website {\n",
    "            label=\"Dataset\";\n",
    "            \"Test set\";\n",
    "            \"Validation set\";\n",
    "            \"Training set\";\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "save_gv(\"split_dataset\", data, is_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/split_dataset.png \"How to split you dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we train a model with all our data and evaluate the model using that same data, we would not be able to tell how well our model can perform on data it hasn’t seen since the model already has all the answers in the training set. Indeed, it could be \n",
    "overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this, we split our dataset into two sets: the *training set* and the *validation set* which is used only for evaluation (and not for the training). This lets us test that the model learns lessons from the training data that generalize to new data, the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we as human can also cheat! Indeed, in realistic scenarios we are likely to explore many versions of a model by choosing various *hyperparameters* (parameters about parameters) : network architecture, learning rates, data augmentation strategies, and other factors we will discuss in upcoming chapters. So, just as the automatic training process is in danger of overfitting the training data, we are in danger of overfitting the validation data through human trial and error and exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to introduce another level of even more highly reserved data, the *test set*. Just as we hold back the validation data from the training process, we must hold back the test set data even ourselves. It cannot be used to improve the model; it can only be used to evaluate the model at the very end of our efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Judgment in Defining Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key property of the validation and test sets is that they must be **representative of the new data you will see in the future**. Therefore, you shouldn't always choose a random subset of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following situations, how should you split the training set and the validation set ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are using historical data to build a model to [predict the future sales in a chain of Ecuadorian grocery stores](https://www.kaggle.com/c/favorita-grocery-sales-forecasting) as you can see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/timeseries1.png \"A time series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Kaggle [distracted driver competition](https://www.kaggle.com/c/state-farm-distracted-driver-detection), the independent variables are pictures of drivers at the wheel of a car, and the dependant variables are categories such as texting, eating, or safely looking ahead. Lots of pictures are of the same drivers in different positions, as we can see in this figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/driver.png \"Two pictures from the training data, showing the same driver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are trying to create an algorithm to distinguish dogs and cats for the [Kaggle Dogs vs. Cats competition](https://www.kaggle.com/c/dogs-vs-cats/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the [Kaggle fisheries competition](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring) was to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set of Kaggle on which you'll do your predictions consisted of boats that didn't appear in the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/timeseries3.png \"A good training subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You are using historical data to build a model to predict the future sales in a chain\n",
    "\n",
    "Therefore, we should take a part of the newest data in our validation set in order to be **representative of the new data you will see in the future**. \n",
    "\n",
    "Indeed, a random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you'll need in production), as we can see :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/dl_for_coders_01/timeseries2.png \"Random training subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lots of pictures are of the same drivers in different positions.\n",
    "\n",
    "The validation data should consists of images of people that don't appear in the training set in order to be **representative of the new data you will see in the future**.\n",
    "\n",
    "Indeed, if you used all the people in training your model, your model might be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly is a good answer (since it will keep a good ratio between classes in the sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The test set consisted of boats that didn't appear in the training data. \n",
    "\n",
    "This means that you'd want your validation set to include boats that are not in the training set in order to be **representative of the new data you will see in the future**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to this link and learn the flash cards. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Empty space -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Empty space -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{% bibliography --cited %}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f84e6c513c59ca62dd4188e281641d696cc3851154e12fdd779776f46eb6c727"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
